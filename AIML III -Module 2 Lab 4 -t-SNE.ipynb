{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPW9chCJluDkvZ6j0HY6OTG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Allekarthik/AIML_Projects_and_labs/blob/main/AIML%20III%20-Module%202%20Lab%204%20-t-SNE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdgVZCTeyquh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise:\n",
        "Now that you understand t-SNE a bit better, can you point out some differences between PCA and t-SNE. What are the advantages/disadvantages of one over the other?\n",
        "Pointers:\n",
        "a. Which of the two algorithms is linear and which one is non-linear?\n",
        "b. How does the non-linearity in one of these two algorithms help in capturing certain data sets?\n",
        "c. PCA is known to keep points which were further apart in the higher dimension, far apart in the lower dimension as well. Does t-SNE do the same? Or does it try to preserve local neighbourhood?\n",
        "d. Can you comment on which one of the two is computationally more expensive?\n",
        "\n",
        "How does the computational complexity and runtime of t-SNE scale with dataset size and dimensionality?\n",
        "\n",
        "What are some limitations or potential pitfalls to be aware of when using t-SNE? (tell atleast 3)"
      ],
      "metadata": {
        "id": "1GW27wcbyrZS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Now that you understand t-SNE a bit better, can you point out some differences between PCA and t-SNE. What are the advantages/disadvantages of one over the other?\n",
        "\n",
        "**Differences between Principal Component Analysis and t-SNE**\n",
        "\n",
        "PCA is a linearly dimensionality reduction.where as t-SNE is non linear technique.\n",
        "\n",
        "PCA preverses global structure where as t-sne perserses local structure\n",
        "\n",
        "\n",
        "PCA is widely used for tasks like noise reduction, visualization, and feature extraction in high-dimensional data analysis. t-SNE is commonly used for visualizing high-dimensional data in a lower-dimensional space, especially in fields like natural language processing (NLP), image analysis, and genomics.\n",
        "\n",
        "**Advantages of PCA over t-SNE: **\n",
        "\n",
        "PCA is computationally efficient and scales well with large datasets.\n",
        "PCA preserves global structure and variance, making it useful for understanding the overall data distribution.\n",
        "PCA produces interpretable components that can be directly related to the original features.\n",
        "\n",
        "**Advantages of t-SNE over PCA:**\n",
        "\n",
        "t-SNE is better at revealing the local structure and clusters within the data, making it more suitable for visualization and exploration.\n",
        "t-SNE can handle non-linear relationships between variables, whereas PCA assumes linear relationships.\n",
        "t-SNE can often provide a more insightful visualization of complex datasets by revealing inherent patterns and groupings.\n",
        "\n",
        "**Disadvantages of PCA compared to t-SNE:**\n",
        "\n",
        "PCA may not capture intricate local relationships and clusters as effectively as t-SNE.\n",
        "PCA is limited to linear transformations and may not be suitable for datasets with complex non-linear structures.\n",
        "\n",
        "**Disadvantages of t-SNE compared to PCA:**\n",
        "t-SNE is computationally expensive and may be impractical for very large datasets.\n",
        "t-SNE results can vary depending on parameter settings (e.g., perplexity), requiring careful tuning.\n",
        "t-SNE does not provide an explicit mapping back to the original features, making it less interpretable in terms of feature contributions.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nUHMO4nbyui0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a. Which of the two algorithms is linear and which one is non-linear?\n",
        "PCA is linear where t-sne is non linear\n"
      ],
      "metadata": {
        "id": "KVKS4Xs94kiJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1dWJVlpm4klm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. How does the non-linearity in one of these two algorithms help in capturing certain data sets?\n",
        "\n",
        "t-sne is non linear so its helps in\n",
        ">Capturing Non-linear Relationships\n",
        ">Preservation of Local Structure\n",
        ">Visualization of High-dimensional Data\n",
        ">Handling Manifold Structures\n",
        ">Exploration and Insight Generation\n"
      ],
      "metadata": {
        "id": "-VA6raWf4koQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PCA is known to keep points which were further apart in the higher dimension, far apart in the lower dimension as well. Does t-SNE do the same? Or does it try to preserve local neighbourhood?\n",
        "\n",
        "\n",
        "t-SNE (t-Distributed Stochastic Neighbor Embedding) does not necessarily preserve the exact pairwise distances or global structures like PCA does. Instead, t-SNE focuses on preserving the local neighborhood relationships between data points in the high-dimensional space when embedding them into a lower-dimensional space.\n"
      ],
      "metadata": {
        "id": "rWXXRJq94kqz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Can you comment on which one of the two is computationally more expensive?\n",
        "\n",
        "In terms of computational expense, t-SNE (t-Distributed Stochastic Neighbor Embedding) is  more expensive than PCA"
      ],
      "metadata": {
        "id": "vJyyN-S14ktM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How does the computational complexity and runtime of t-SNE scale with dataset size and dimensionality?\n",
        "\n",
        "\n",
        "\n",
        "Dataset Size (n):\n",
        "\n",
        "As the number of data points (n) increases, the computational complexity of t-SNE generally scales quadratically or worse. Specifically, the time complexity for t-SNE is often cited as O(n^2) or O(n^3) for typical implementations.\n",
        "The reason for this quadratic scaling is primarily due to the computation of pairwise similarities (affinities) between all pairs of data points in the high-dimensional space. This pairwise computation is necessary for constructing the affinity matrix used in the t-SNE optimization process.\n",
        "Therefore, larger datasets require more pairwise comparisons, leading to increased computational time and memory requirements.\n",
        "\n",
        "Dimensionality (m):\n",
        "t-SNEâ€™s computational complexity with respect to the original dimensionality (m) of the data is less straightforward compared to PCA. However, in practice, t-SNE tends to be more affected by the number of data points (n) rather than the number of dimensions (m).\n",
        "The pairwise similarity computation in t-SNE depends on the distances (often Euclidean distances) between data points in the original high-dimensional space. While the dimensionality (m) affects these distances, its impact on computational complexity is typically overshadowed by the effect of dataset size (n).\n",
        "\n",
        "Runtime and Practical Considerations:\n",
        "Beyond theoretical complexity, the runtime of t-SNE also depends on practical factors such as implementation details, hardware capabilities (CPU vs GPU), and the specific parameters chosen (e.g., perplexity, number of iterations).\n",
        "Large datasets and high-dimensional data can significantly increase the runtime and memory usage of t-SNE. Implementations optimized for performance, such as those leveraging efficient data structures or parallel computing, can mitigate some of these challenges.\n"
      ],
      "metadata": {
        "id": "miyPlXma5mEK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What are some limitations or potential pitfalls to be aware of when using t-SNE? (tell atleast 3)\n",
        "\n",
        "\n",
        "Sensitive to Perplexity Parameter\n",
        ">Computational Intensity and Scalability\n",
        ">Interpretation Challenges\n",
        ">Non-deterministic Nature\n",
        ">Overfitting Small Clusters"
      ],
      "metadata": {
        "id": "JQeWEh095mRk"
      }
    }
  ]
}